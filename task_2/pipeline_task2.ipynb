{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b714c8-8ea8-4992-8773-3e49c021f28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load the NER model (Named Entity Recognition)\n",
    "model_name = \"./trained_model\"  # Path to the saved NER model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)  # Load the tokenizer\n",
    "ner_model = AutoModelForTokenClassification.from_pretrained(model_name)  # Load the NER model\n",
    "\n",
    "# Load the pre-trained image classification model\n",
    "#cv_model = torch.load(\"best_model_image.pth\")  # Load the image classification model weights\n",
    "#cv_model.eval()  # Set the model to evaluation mode (important for inference)\n",
    "\n",
    "cv_model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)  # Загружаем базовую модель с весами\n",
    "num_ftrs = cv_model.fc.in_features\n",
    "cv_model.fc = nn.Linear(num_ftrs, 10)  # Восстанавливаем последний слой\n",
    "\n",
    "# Загрузите веса модели\n",
    "cv_model.load_state_dict(torch.load(\"best_model_image.pth\", map_location=torch.device(\"cpu\")))\n",
    "\n",
    "# Установите режим оценки\n",
    "cv_model.eval()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Image transformation pipeline for pre-processing images before passing them into the model\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize the image to 224x224 (required for most image classification models)\n",
    "    transforms.ToTensor(),  # Convert the image to a tensor\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize the image (standard ImageNet values)\n",
    "])\n",
    "\n",
    "# Function to extract animal names from text using NER (Named Entity Recognition)\n",
    "def extract_animal(text):\n",
    "    # Tokenize the input text and convert it to tensor format for the model\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    # Pass tokens through the NER model to get predictions\n",
    "    outputs = ner_model(**tokens)\n",
    "    # Get the predicted labels for each token\n",
    "    predictions = torch.argmax(outputs.logits, dim=-1)[0].tolist()\n",
    "    # Convert token IDs back to words\n",
    "    words = tokenizer.convert_ids_to_tokens(tokens[\"input_ids\"][0])\n",
    "\n",
    "    # List to store detected animal names\n",
    "    entities = []\n",
    "    for token, pred in zip(words, predictions):\n",
    "        # If the token is labeled as an \"animal\" (class 1), add it to the list\n",
    "        if pred == 1:  # Class 1 represents ANIMAL entities in this model\n",
    "            entities.append(token.replace(\"##\", \"\"))  # Remove subword tokenization (e.g., \"##\" in BERT tokens)\n",
    "\n",
    "    # Return the detected animal names as a single string\n",
    "    return \" \".join(entities)\n",
    "\n",
    "# Function to classify an image and predict the animal in the image\n",
    "def classify_image(image_path):\n",
    "    # Open the image and convert it to RGB (if not already)\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    # Apply the image transformation pipeline (resize, normalize, etc.)\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension (necessary for model input)\n",
    "    animal_classes = ['beaver', 'dolphin', 'otter', 'seal', 'fox', 'spider', 'elephant', 'bear', 'rabbit', 'tiger']\n",
    "    with torch.no_grad():  # No need to compute gradients for inference\n",
    "        outputs = cv_model(image)  # Pass the image through the model\n",
    "        _, predicted = torch.max(outputs, 1)  # Get the index of the predicted class (animal)\n",
    "    \n",
    "    return animal_classes[predicted.item()]  # Return the predicted class index\n",
    "\n",
    "# Main pipeline to verify if the text and image describe the same animal\n",
    "def verify_claim(text, image_path):\n",
    "    # Extract the animal name(s) from the text using the NER model\n",
    "    text_animal = extract_animal(text)\n",
    "    # Classify the image and get the predicted animal class\n",
    "    image_animal = classify_image(image_path)\n",
    "    \n",
    "    # Print the results for both the text and the image\n",
    "    print(f\"From the text: {text_animal}\")\n",
    "    print(f\"From the image: {image_animal}\")\n",
    "\n",
    "    # Compare the predicted animal from the text and the image\n",
    "    return text_animal.lower() == image_animal.lower()  # Return True if both match, else False\n",
    "\n",
    "# Example test\n",
    "text_input = input(str('Input text: '))  # Prompt the user to input text\n",
    "image_path = \"Download_file.jpg\"  # Path to the image file (could be dynamically passed in real use case)\n",
    "result = verify_claim(text_input, image_path)  # Run the verification function\n",
    "\n",
    "# Print the result\n",
    "print(\"✅ Correct!\" if result else \"❌ Incorrect!\")  # Output whether the claim is correct or not"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
